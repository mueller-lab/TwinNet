{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7597b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf.config.list_physical_devices('GPU')\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4705ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from twinnet_tools.tnconfig import ProjectConfig\n",
    "from twinnet_tools.tnmodel import TNToolsDistanceLayer\n",
    "from twinnet_tools.tnmodel import TNToolsModel\n",
    "from twinnet_tools.tntraining import TNToolsTrainingImages, TNToolsTrainingPaths\n",
    "\n",
    "os.environ[\"OPENCV_LOG_LEVEL\"]=\"FATAL\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "config = ProjectConfig(\"twinnet_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163483d",
   "metadata": {},
   "source": [
    "Make tool instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224, 224 \n",
    "it = TNToolsTrainingImages(img_height, 280, img_width, 280)\n",
    "pg = TNToolsTrainingPaths(img_height, 280, img_width, 280, pattern_glob_files=\"*.tif\")\n",
    "\n",
    "image_count = 1000000\n",
    "\n",
    "batchSize = 256\n",
    "prefetch = 8\n",
    "buffer_size=1024 #round(image_count * 1.2)\n",
    "\n",
    "outFolder = '../models/model1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3fff9a",
   "metadata": {},
   "source": [
    "# Step 1: Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_paths_datasets_directories = [\"./dir_dataset_1\",\n",
    "#                                   \"./dir_dataset_2\"]\n",
    "list_paths_datasets_directories1 = [\"../trainData/zfish_285C\"\n",
    "                                   ]\n",
    "\n",
    "list_paths_jsons_exclude1 = [str(i) + '/EMBRYOS_TO_EXCLUDE.json' for i in list_paths_datasets_directories1]\n",
    "\n",
    "print(list_paths_datasets_directories1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_anchor, paths_positive, paths_negative = pg.procedure_paths_binary(list_paths_datasets_directories1,\n",
    "                                                                         list_paths_jsons_exclude1,\n",
    "                                                                         image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_anchor2, paths_positive2, paths_negative2 = pg.procedure_paths_binary(list_paths_datasets_directories1,\n",
    "                                                                            list_paths_jsons_exclude1,\n",
    "                                                                            image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_anchor3, paths_positive3, paths_negative3 = pg.procedure_paths_binary(list_paths_datasets_directories1,\n",
    "                                                                            list_paths_jsons_exclude1,\n",
    "                                                                            image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anchor = tf.data.Dataset.from_tensor_slices(paths_anchor)\n",
    "dataset_positive = tf.data.Dataset.from_tensor_slices(paths_positive)\n",
    "dataset_negative = tf.data.Dataset.from_tensor_slices(paths_negative)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_anchor, dataset_positive, dataset_negative))\n",
    "dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "dataset = dataset.map(it.parse_triple_fn)\n",
    "\n",
    "train_dataset = dataset.take(round(image_count * 0.8))\n",
    "val_dataset = dataset.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset = train_dataset.batch(batchSize, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(prefetch)\n",
    "\n",
    "val_dataset = val_dataset.batch(batchSize, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(prefetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606bf439",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anchor2 = tf.data.Dataset.from_tensor_slices(paths_anchor2)\n",
    "dataset_positive2 = tf.data.Dataset.from_tensor_slices(paths_positive2)\n",
    "dataset_negative2 = tf.data.Dataset.from_tensor_slices(paths_negative2)\n",
    "\n",
    "dataset2 = tf.data.Dataset.zip((dataset_anchor2, dataset_positive2, dataset_negative2))\n",
    "dataset2 = dataset2.shuffle(buffer_size=buffer_size)\n",
    "dataset2 = dataset2.map(it.augment_triple_one)\n",
    "\n",
    "train_dataset2 = dataset2.take(round(image_count * 0.8))\n",
    "val_dataset2 = dataset2.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset2 = train_dataset2.batch(batchSize, drop_remainder=False)\n",
    "train_dataset2 = train_dataset2.prefetch(prefetch)\n",
    "\n",
    "val_dataset2 = val_dataset2.batch(batchSize, drop_remainder=False)\n",
    "val_dataset2 = val_dataset2.prefetch(prefetch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e573e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anchor3 = tf.data.Dataset.from_tensor_slices(paths_anchor3)\n",
    "dataset_positive3 = tf.data.Dataset.from_tensor_slices(paths_positive3)\n",
    "dataset_negative3 = tf.data.Dataset.from_tensor_slices(paths_negative3)\n",
    "\n",
    "dataset3 = tf.data.Dataset.zip((dataset_anchor3, dataset_positive3, dataset_negative3))\n",
    "dataset3 = dataset3.shuffle(buffer_size=buffer_size)\n",
    "dataset3 = dataset3.map(it.augment_triple_two)\n",
    "\n",
    "train_dataset3 = dataset3.take(round(image_count * 0.8))\n",
    "val_dataset3 = dataset3.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset3 = train_dataset3.batch(batchSize, drop_remainder=False)\n",
    "train_dataset3 = train_dataset3.prefetch(prefetch)\n",
    "\n",
    "val_dataset3 = val_dataset3.batch(batchSize, drop_remainder=False)\n",
    "val_dataset3 = val_dataset3.prefetch(prefetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d459961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(anchor, positive, negative):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "\n",
    "    def show(ax, image):\n",
    "        ax.imshow(image / 255, cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "    axs = fig.subplots(4, 3)\n",
    "    for i in range(4):\n",
    "        show(axs[i, 0], anchor[i])\n",
    "        show(axs[i, 1], positive[i])\n",
    "        show(axs[i, 2], negative[i])\n",
    "\n",
    "\n",
    "visualize(*list(train_dataset.take(1).as_numpy_iterator())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee29923",
   "metadata": {},
   "source": [
    "# Step 2: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef5dc9",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff41f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = tf.keras.applications.resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=(img_height, img_width) + (3,), include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)\n",
    "\n",
    "embedding = tf.keras.models.Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "    if layer.name == \"conv5_block1_out\":\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b019866",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_input = tf.keras.layers.Input(name=\"anchor\", shape=(img_height, img_width) + (3,))\n",
    "positive_input = tf.keras.layers.Input(name=\"positive\", shape=(img_height, img_width) + (3,))\n",
    "negative_input = tf.keras.layers.Input(name=\"negative\", shape=(img_height, img_width) + (3,))\n",
    "\n",
    "distances = TNToolsDistanceLayer()(\n",
    "    embedding(tf.keras.applications.resnet.preprocess_input(anchor_input)),\n",
    "    embedding(tf.keras.applications.resnet.preprocess_input(positive_input)),\n",
    "    embedding(tf.keras.applications.resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "twin_network = tf.keras.models.Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")\n",
    "\n",
    "twin_network_model = TNToolsModel(twin_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5dbf16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twin_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d991c72",
   "metadata": {},
   "source": [
    "Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = outFolder+'/checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41080d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5,\n",
    ")\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32629af",
   "metadata": {},
   "source": [
    "Run training:\n",
    "- 6 runs, 2 with a different dataset\n",
    "- 1000000 image triplets per dataset\n",
    "- 10 epochs per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e07f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twin_network_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f02b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_dir = outFolder+\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = twin_network_model.fit(train_dataset, epochs=10, callbacks=[early_stopping, model_checkpoint_callback, tensorboard_callback], validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_network_model.compute_output_shape(input_shape=((None, 224,224,3), (None, 224,224,3),(None, 224,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_network_model.save(outFolder+'/dir_dst_model_epochs_10/')\n",
    "embedding.save_weights(outFolder+'/dir_dst_model_epochs_10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b471a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_dir = outFolder+\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history2 = twin_network_model.fit(train_dataset2, epochs=20, initial_epoch=10, callbacks=[early_stopping, model_checkpoint_callback, tensorboard_callback], validation_data=val_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_network_model.save(outFolder+'/dir_dst_model_epochs_20/')\n",
    "embedding.save_weights(outFolder+'/dir_dst_model_epochs_20/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd183fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = outFolder+\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history3 = twin_network_model.fit(train_dataset3, epochs=30, initial_epoch=20, callbacks=[early_stopping, model_checkpoint_callback,tensorboard_callback], validation_data=val_dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39241bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_network_model.save(outFolder+'/dir_dst_model_epochs_30/')\n",
    "embedding.save_weights(outFolder+'/dir_dst_model_epochs_30/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43a6b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_dir = outFolder+\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history4 = twin_network_model.fit(train_dataset3, epochs=40, initial_epoch=30, callbacks=[early_stopping, model_checkpoint_callback,tensorboard_callback], validation_data=val_dataset3)\n",
    "twin_network_model.save(outFolder+'/dir_dst_model_epochs_40/')\n",
    "embedding.save_weights(outFolder+'/dir_dst_model_epochs_40/')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
