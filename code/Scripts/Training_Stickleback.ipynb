{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e01d82",
   "metadata": {},
   "source": [
    "# Training of a Twin Network model: Stickleback (Gasterosteus aculeatus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef446b2",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [General](#first-bullet)\n",
    "* [Load dataset](#second-bullet)\n",
    "* [Load model](#third-bullet)\n",
    "* [Training](#fourth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d7215f",
   "metadata": {},
   "source": [
    "## General <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb4f16",
   "metadata": {},
   "source": [
    "General imports and class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4dbde2",
   "metadata": {},
   "source": [
    "Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4705ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from twinnet_tools.tnconfig import ProjectConfig\n",
    "from twinnet_tools.tnmodel import TNToolsDistanceLayer\n",
    "from twinnet_tools.tnmodel import TNToolsModel\n",
    "from twinnet_tools.tntraining import TNToolsTrainingImages, TNToolsTrainingPaths\n",
    "\n",
    "os.environ[\"OPENCV_LOG_LEVEL\"]=\"FATAL\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a91668",
   "metadata": {},
   "source": [
    "Load config file and paths from config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProjectConfig(\"twinnet_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths_script = config.json[\"TrainingStickleback\"]\n",
    "dir_data_src = config_paths_script[\"dir_data_src\"]\n",
    "dir_data_dst = config_paths_script[\"dir_data_dst\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d3843",
   "metadata": {},
   "source": [
    "Prepare paths to save outputs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelId=\"model1\"\n",
    "\n",
    "# Output path\n",
    "outFolder = f\"{dir_data_dst}/{modelId}\"\n",
    "\n",
    "if not os.path.exists(outFolder):\n",
    "    os.makedirs(outFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb6970",
   "metadata": {},
   "source": [
    "Make tool instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224, 224 \n",
    "it = TNToolsTrainingImages(img_height, 500, img_width, 500)\n",
    "pg = TNToolsTrainingPaths(img_height, 400, img_width, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c6b71e",
   "metadata": {},
   "source": [
    "Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34632f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 64\n",
    "image_count = 150000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052bf80",
   "metadata": {},
   "source": [
    "## Load dataset <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee0211",
   "metadata": {},
   "source": [
    "Load paths of datasets to use for image triplet preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paths_datasets_directories = dir_data_src\n",
    "                                   \n",
    "list_paths_jsons_exclude = [str(i) + '/EMBRYOS_TO_EXCLUDE.json' for i in list_paths_datasets_directories]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530f2e2",
   "metadata": {},
   "source": [
    "Sort image paths to image triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_anchor, paths_positive, paths_negative = pg.procedure_paths_binary(list_paths_datasets_directories,\n",
    "                                                                         list_paths_jsons_exclude,\n",
    "                                                                         image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_anchor2, paths_positive2, paths_negative2 = pg.procedure_paths_binary(list_paths_datasets_directories,\n",
    "                                                                            list_paths_jsons_exclude,\n",
    "                                                                            image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_anchor3, paths_positive3, paths_negative3 = pg.procedure_paths_binary(list_paths_datasets_directories,\n",
    "                                                                            list_paths_jsons_exclude,\n",
    "                                                                            image_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56170cc8",
   "metadata": {},
   "source": [
    "Make tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef2e7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anchor = tf.data.Dataset.from_tensor_slices(paths_anchor)\n",
    "dataset_positive = tf.data.Dataset.from_tensor_slices(paths_positive)\n",
    "dataset_negative = tf.data.Dataset.from_tensor_slices(paths_negative)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_anchor, dataset_positive, dataset_negative))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(it.parse_triple_fn)\n",
    "\n",
    "train_dataset = dataset.take(round(image_count * 0.8))\n",
    "val_dataset = dataset.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset = train_dataset.batch(batchSize, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "val_dataset = val_dataset.batch(batchSize, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606bf439",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anchor2 = tf.data.Dataset.from_tensor_slices(paths_anchor2)\n",
    "dataset_positive2 = tf.data.Dataset.from_tensor_slices(paths_positive2)\n",
    "dataset_negative2 = tf.data.Dataset.from_tensor_slices(paths_negative2)\n",
    "\n",
    "dataset2 = tf.data.Dataset.zip((dataset_anchor2, dataset_positive2, dataset_negative2))\n",
    "dataset2 = dataset2.shuffle(buffer_size=1024)\n",
    "dataset2 = dataset2.map(it.augment_triple_one)\n",
    "\n",
    "train_dataset2 = dataset2.take(round(image_count * 0.8))\n",
    "val_dataset2 = dataset2.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset2 = train_dataset2.batch(batchSize, drop_remainder=False)\n",
    "train_dataset2 = train_dataset2.prefetch(8)\n",
    "\n",
    "val_dataset2 = val_dataset2.batch(batchSize, drop_remainder=False)\n",
    "val_dataset2 = val_dataset2.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e573e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anchor3 = tf.data.Dataset.from_tensor_slices(paths_anchor3)\n",
    "dataset_positive3 = tf.data.Dataset.from_tensor_slices(paths_positive3)\n",
    "dataset_negative3 = tf.data.Dataset.from_tensor_slices(paths_negative3)\n",
    "\n",
    "dataset3 = tf.data.Dataset.zip((dataset_anchor3, dataset_positive3, dataset_negative3))\n",
    "dataset3 = dataset3.shuffle(buffer_size=1024)\n",
    "dataset3 = dataset3.map(it.augment_triple_two)\n",
    "\n",
    "train_dataset3 = dataset3.take(round(image_count * 0.8))\n",
    "val_dataset3 = dataset3.skip(round(image_count * 0.8))\n",
    "\n",
    "train_dataset3 = train_dataset3.batch(batchSize, drop_remainder=False)\n",
    "train_dataset3 = train_dataset3.prefetch(8)\n",
    "\n",
    "val_dataset3 = val_dataset3.batch(batchSize, drop_remainder=False)\n",
    "val_dataset3 = val_dataset3.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d459961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(anchor, positive, negative):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "\n",
    "    def show(ax, image):\n",
    "        ax.imshow(image / 255, cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "\n",
    "    axs = fig.subplots(4, 3)\n",
    "    for i in range(4):\n",
    "        show(axs[i, 0], anchor[i])\n",
    "        show(axs[i, 1], positive[i])\n",
    "        show(axs[i, 2], negative[i])\n",
    "\n",
    "\n",
    "visualize(*list(train_dataset.take(1).as_numpy_iterator())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee29923",
   "metadata": {},
   "source": [
    "## Load model <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef5dc9",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff41f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = tf.keras.applications.resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=(img_height, img_width) + (3,), include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)\n",
    "\n",
    "embedding = tf.keras.models.Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "    if layer.name == \"conv5_block1_out\":\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b019866",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_input = tf.keras.layers.Input(name=\"anchor\", shape=(img_height, img_width) + (3,))\n",
    "positive_input = tf.keras.layers.Input(name=\"positive\", shape=(img_height, img_width) + (3,))\n",
    "negative_input = tf.keras.layers.Input(name=\"negative\", shape=(img_height, img_width) + (3,))\n",
    "\n",
    "distances = TNToolsDistanceLayer()(\n",
    "    embedding(tf.keras.applications.resnet.preprocess_input(anchor_input)),\n",
    "    embedding(tf.keras.applications.resnet.preprocess_input(positive_input)),\n",
    "    embedding(tf.keras.applications.resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "twin_network = tf.keras.models.Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5dbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d991c72",
   "metadata": {},
   "source": [
    "Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = outFolder+'/checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41080d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5,\n",
    ")\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = outFolder+\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n",
    "                                                      histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf07872d",
   "metadata": {},
   "source": [
    "## Training <a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32629af",
   "metadata": {},
   "source": [
    "Run training:\n",
    "- 150000 image triplets per dataset\n",
    "- 3 runs, each run with a different dataset\n",
    "- 10 epochs per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e07f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_network_model = TNToolsModel(twin_network)\n",
    "twin_network_model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), \n",
    "                           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783fa2e",
   "metadata": {},
   "source": [
    "Training iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = twin_network_model.fit(train_dataset, \n",
    "                                 epochs=10, \n",
    "                                 callbacks=[early_stopping, \n",
    "                                            model_checkpoint_callback, \n",
    "                                            tensorboard_callback], \n",
    "                                 validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "twin_network_model.compute_output_shape(\n",
    "    input_shape=((None, 224,224,3), \n",
    "                 (None, 224,224,3),\n",
    "                 (None, 224,224,3))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.save(outFolder+'/dir_dst_model_epochs_10/')\n",
    "embedding.save_weights(outFolder+'/dir_dst_model_epochs_10_weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64c574",
   "metadata": {},
   "source": [
    "Training iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b471a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = outFolder+\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history2 = twin_network_model.fit(train_dataset2, epochs=20, initial_epoch=10, callbacks=[early_stopping, model_checkpoint_callback, tensorboard_callback], validation_data=val_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.save(outFolder+'/dir_dst_model_epochs_20/')\n",
    "embedding.save_weights(outFolder+'/dir_dst_model_epochs_20_weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c6f97",
   "metadata": {},
   "source": [
    "Training iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd183fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = outFolder+\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history3 = twin_network_model.fit(train_dataset3, epochs=30, initial_epoch=20, callbacks=[early_stopping, model_checkpoint_callback,tensorboard_callback], validation_data=val_dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b64d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.save(outFolder+'/dir_dst_model_epochs_30/')\n",
    "embedding.save_weights(outFolder+'/dir_dst_model_epochs_30_weights/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
