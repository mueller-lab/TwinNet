{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d38a669",
   "metadata": {},
   "source": [
    "# Evaluations of variability in self-similarity matrices: Zebrafish (Danio rerio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0eb452",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [General](#first-bullet)\n",
    "* [Load paths](#second-bullet)\n",
    "* [Load model](#third-bullet)\n",
    "* [Calculate embeddings and similarities](#fourth-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5eb03",
   "metadata": {},
   "source": [
    "## General <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5771994",
   "metadata": {},
   "source": [
    "General imports and class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce196c5",
   "metadata": {},
   "source": [
    "Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f950309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import HTML, Image,SVG,display\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "from twinnet_tools.tnautoregression import TNToolsAutoregression\n",
    "from twinnet_tools.tngeneral import TNToolsGeneral\n",
    "from twinnet_tools.tninference import TNToolsEmbeddings\n",
    "from twinnet_tools.tninference import TNToolsImages\n",
    "from twinnet_tools.tninference import TNToolsSimilarities\n",
    "from twinnet_tools.tnmodel import TNToolsNetwork\n",
    "from twinnet_tools.tnplot import TNToolsPlot\n",
    "\n",
    "from twinnet_tools.tnconfig import ProjectConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3858f",
   "metadata": {},
   "source": [
    "Load config file and paths from config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefcfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ProjectConfig(\"twinnet_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2afcf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "srcpath = '../TwinNet-main/'\n",
    "dir_root_scripts = os.path.join(srcpath, config.json[\"dir_scripts\"])\n",
    "\n",
    "path_models_zebrafish = '../temperature_zFish/models/'\n",
    "model_names = ['Model_zfish_var01', 'Model_zfish_var02', 'Model_zfish_var03','Model_zfish_var04','Model_zfish_var05','Model_zfish_var06', 'Model_zfish_var07', 'Model_zfish_var08', 'Model_zfish_var09', 'Model_zfish_var10']\n",
    "\n",
    "config_paths_script = config.json[\"Autoregression_zebrafish\"]\n",
    "dir_data = '../temperature_zFish/testData/'\n",
    "path_src_data_test_json = os.path.join(dir_data,'test_embryos_sorted.json')\n",
    "path_dst = '../temperature_zFish/results_Autoregression_variability/'\n",
    "\n",
    "\n",
    "num_images = 720\n",
    "time_interval = 2 #in minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd2c879",
   "metadata": {},
   "source": [
    "Prepare class instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_autoregression = TNToolsAutoregression()\n",
    "tools_general = TNToolsGeneral()\n",
    "tools_model = TNToolsNetwork()\n",
    "tools_plot = TNToolsPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d232d0c",
   "metadata": {},
   "source": [
    "Adjust matplotlib parameters to save plots as .svg files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ae21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rc_params = {'text.usetex': False,\n",
    "                'svg.fonttype': 'none'}\n",
    "mpl.rcParams.update(new_rc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda54c4",
   "metadata": {},
   "source": [
    "## Load paths <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee7a71",
   "metadata": {},
   "source": [
    "Load test data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46db25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embryos_test = [f\"{dir_data}/{p[2:]}/\".replace('//', '/').replace('./', '') \n",
    "                for p in sorted(tools_general.fn_json_load(\n",
    "                    path_src_data_test_json)['normal_bright_complete'])\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embryo_test = embryos_test[2]\n",
    "#print(embryo_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba12e3c",
   "metadata": {},
   "source": [
    "Specify directory to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_dst_similarities = f\"{path_dst}/similarities\"\n",
    "#dir_dst_similarities_path = Path( dir_dst_similarities )\n",
    "#dir_dst_similarities_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691a241",
   "metadata": {},
   "source": [
    "## Load models <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6b97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_models = []\n",
    "\n",
    "for model_name in sorted(model_names):\n",
    "    path_model_zebrafish = os.path.join(path_models_zebrafish, model_name+\".h5\")\n",
    "    print(path_model_zebrafish)\n",
    "    tn_model_embedding = tools_model.tn_embedding_load(path_model_zebrafish)\n",
    "    all_models.append(tn_model_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e4f57",
   "metadata": {},
   "source": [
    "## Calculate embeddings and similarities <a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0adb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_similarities = []\n",
    "all_paths_imgs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for embryo_test in embryos_test:\n",
    "    sims = []\n",
    "    paths_i = []\n",
    "    for counter, tn_model_embedding in enumerate(all_models):\n",
    "        print(f\"Calculating: {embryo_test} with model {counter}\")\n",
    "        similarities_test, paths_imgs = tools_autoregression.similarities_self_calculate(embryo_test, tn_model_embedding)\n",
    "        sims.append(similarities_test)\n",
    "        paths_i.append(paths_imgs)\n",
    "        \n",
    "    all_similarities.append(sims) \n",
    "    all_paths_imgs.append(paths_i)\n",
    "    \n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time    \n",
    "print(processing_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aad918",
   "metadata": {},
   "source": [
    "Transform similarities to 2D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee86375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot 2d matrix and exprot svg\n",
    "\n",
    "def plot_similarity_2d(xs_grid, ys_grid, zs_grid_plot, time_interval, outpath, maxVal):\n",
    "        \"\"\"\n",
    "        Plot similarities of images from a time-series image sequence\n",
    "        of an embryo as two-dimensional matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        intervals: int/float\n",
    "            Time intervals (min), at which test embryo images\n",
    "            were acquired. Use this\n",
    "            to adjust axis labels to be labelled with minutes.\n",
    "            \n",
    "        outpath: string\n",
    "            Path to save the svg image\n",
    "        \"\"\"\n",
    "        #print(f\" min {np.amin(zs_grid_plot)}, max {np.amax(zs_grid_plot)} \")\n",
    "        \n",
    "        num_imgs_test = len(zs_grid_plot[0]) + 1\n",
    "        plot_atp_min_correction = time_interval\n",
    "        plot_xy_ticks = list(range(0, num_imgs_test, 100))\n",
    "\n",
    "        plot_colors_hlf = plt.cm.viridis  #mpl.colormaps['viridis'] \n",
    "        plot_fig_dpi = 300\n",
    "        plot_fig_size_square = (4, 4)\n",
    "        plot_fontsize_small = 8\n",
    "        plot_fontsize_large = 6\n",
    "        \n",
    "        # Figure\n",
    "        f, ax = plt.subplots(dpi=plot_fig_dpi,\n",
    "                             figsize=plot_fig_size_square)\n",
    "        f.tight_layout(rect=[0.0, 0.0, 0.8, 1.0])\n",
    "\n",
    "        # Plot\n",
    "        ax.imshow(zs_grid_plot,\n",
    "                  cmap=plot_colors_hlf, \n",
    "                  vmin=0, vmax=maxVal)\n",
    "\n",
    "        # Labels and titles\n",
    "        ax.tick_params(axis='both',\n",
    "                       which='both',\n",
    "                       labelsize=plot_fontsize_small)\n",
    "        ax.set_xlabel('Time (min)',\n",
    "                      fontsize=plot_fontsize_large)\n",
    "        ax.set_ylabel('Time (min)',\n",
    "                      fontsize=plot_fontsize_large)\n",
    "        ax.set_xlim(left=0,\n",
    "                    right=num_imgs_test-1)\n",
    "        ax.set_ylim(bottom=0,\n",
    "                    top=num_imgs_test-1)\n",
    "        ax.set_xticks(plot_xy_ticks,\n",
    "                      [str(a * plot_atp_min_correction)\n",
    "                       for a in plot_xy_ticks],\n",
    "                      fontsize=plot_fontsize_small)\n",
    "        ax.set_yticks(plot_xy_ticks,\n",
    "                      [str(a * plot_atp_min_correction)\n",
    "                       for a in plot_xy_ticks],\n",
    "                      fontsize=plot_fontsize_small)\n",
    "\n",
    "        divider = make_axes_locatable(ax)\n",
    "        sm = plt.cm.ScalarMappable(cmap=plot_colors_hlf, norm=plt.Normalize(vmin=0, vmax=maxVal))\n",
    "        cax = divider.append_axes(\"right\",\n",
    "                                  size=\"5%\",\n",
    "                                  pad=0.05)\n",
    "        cax.tick_params(axis='both',\n",
    "                        which='both',\n",
    "                        labelsize=plot_fontsize_small)\n",
    "        cbar = f.colorbar(sm,\n",
    "                          cmap=plot_colors_hlf,\n",
    "                          cax=cax)\n",
    "        cbar.ax.set_ylabel('Cosine similarity Ï•',\n",
    "                           fontsize=plot_fontsize_large)\n",
    "\n",
    "        plt.savefig(outpath)\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "def get_arrays_stats(similarities):\n",
    "    \n",
    "    # Stack the arrays along a new axis (axis=0)\n",
    "    stacked_arrays = np.stack(similarities, axis=0)\n",
    "\n",
    "    print(f\"Embryos similarities: {stacked_arrays.shape} \")\n",
    "\n",
    "    # Calculate the average array while handling NaN values\n",
    "    average_array = np.nanmean(stacked_arrays, axis=0)\n",
    "\n",
    "    # Calculate the median array while handling NaN values\n",
    "    median_array = np.nanmedian(stacked_arrays, axis=0)\n",
    "\n",
    "    # Calculate the min array while handling NaN values\n",
    "    min_array = np.nanmin(stacked_arrays, axis=0)\n",
    "\n",
    "    # Calculate the max array while handling NaN values\n",
    "    max_array = np.nanmax(stacked_arrays, axis=0)\n",
    "\n",
    "    # Calculate the standard deviation while handling NaN values\n",
    "    std_array = np.nanstd(stacked_arrays, axis=0)\n",
    "\n",
    "    # Calculate the coefficient of variation (CV) in percentage\n",
    "    cv_array = (std_array / average_array)\n",
    "\n",
    "    return average_array, median_array, min_array, max_array, std_array, cv_array\n",
    "\n",
    "def export_images_stats(xs_grid, ys_grid, embryo_similarities_list, path_dst, name, time_interval):\n",
    " \n",
    "    average_array, median_array, min_array, max_array, std_array, cv_array = get_arrays_stats(embryo_similarities_list)\n",
    "\n",
    "    # Export images\n",
    "    path_save=f\"{path_dst}/{name}_avg_similarities.svg\"\n",
    "    plot_similarity_2d(xs_grid, ys_grid, average_array, time_interval, path_save, 1.0)\n",
    "    path_save=f\"{path_dst}/{name}_median_similarities.svg\"\n",
    "    plot_similarity_2d(xs_grid, ys_grid, median_array, time_interval, path_save, 1.0)\n",
    "    path_save=f\"{path_dst}/{name}_min_similarities.svg\"\n",
    "    plot_similarity_2d(xs_grid, ys_grid, min_array, time_interval, path_save, 1.0)\n",
    "    path_save=f\"{path_dst}/{name}_max_similarities.svg\"\n",
    "    plot_similarity_2d(xs_grid, ys_grid, max_array, time_interval, path_save, 1.0)\n",
    "    path_save=f\"{path_dst}/{name}_std_similarities.svg\"\n",
    "    plot_similarity_2d(xs_grid, ys_grid, std_array, time_interval, path_save, 1.0)\n",
    "    path_save=f\"{path_dst}/{name}_cv_similarities.svg\"\n",
    "    plot_similarity_2d(xs_grid, ys_grid, cv_array, time_interval, path_save, 2.0)\n",
    "\n",
    "    return average_array, median_array, min_array, max_array, std_array, cv_array\n",
    "\n",
    "\n",
    "def get_closest_element_array(stacked_arrays, average_array):\n",
    "\n",
    "    # Calculate the absolute differences between each array in stacked_arrays and average_array\n",
    "    differences = np.abs(stacked_arrays - average_array)\n",
    "\n",
    "    # Sum the absolute differences along both axes to get the Manhattan distances\n",
    "    distances = np.sum(differences, axis=(1, 2)) \n",
    "\n",
    "    # Normalize distances by the total number of elements in each 2D array\n",
    "    total_elements_per_array = stacked_arrays.shape[1] * stacked_arrays.shape[2]\n",
    "    distances = distances / total_elements_per_array\n",
    "\n",
    "\n",
    "    # Find the index of the array that is closest to the average\n",
    "    closest_index = np.argmin(distances)\n",
    "    \n",
    "    \n",
    "    return closest_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01bb84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f\"Similarities calculated for: {len(all_similarities)} embryo with {len(all_similarities[0])} models\")\n",
    "#from skimage.filters import threshold_triangle\n",
    "all_similarities_array = []\n",
    "\n",
    "\n",
    "for counterEmbryo, embryo_sim in enumerate(all_similarities):\n",
    "    simsEmbryo = []\n",
    "    for counterModel, similarities_test in enumerate(embryo_sim):\n",
    "        num_imgs = len(all_paths_imgs[counterEmbryo][counterModel])\n",
    "        #print(f\"Embryo: {counterEmbryo} model {counterModel} : {num_imgs} images\")\n",
    "        if num_imgs == num_images :\n",
    "            xs_grid, ys_grid, similarities_test_array = tools_autoregression.fn_2d_sims_to_arrays(\n",
    "                similarities_test,\n",
    "                num_imgs,\n",
    "                square=True\n",
    "            )\n",
    "            \n",
    "            # Create a mask for NaN values\n",
    "            #nan_mask = np.isnan(similarities_test_array)\n",
    "            # Calculate Triangle threshold for non-NaN values\n",
    "            #threshold_value = threshold_triangle(similarities_test_array[~nan_mask])\n",
    "            # Set elements below the threshold to zero\n",
    "            #similarities_test_array[similarities_test_array < threshold_value] = 0\n",
    "\n",
    "            simsEmbryo.append(np.array(similarities_test_array)) \n",
    "            \n",
    "        else:\n",
    "            print(\"ERROR in number of images!!!!!!!!!!!!!!!\")\n",
    "\n",
    "    all_similarities_array.append(simsEmbryo)        \n",
    "\n",
    "print(f\"2D Similarities calculated for: {len(all_similarities_array)} embryo with {len(all_similarities_array[0])} models\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d990c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average ensamble similarities for each embryo\n",
    "\n",
    "avg_similarities = []\n",
    "std_similarities = []\n",
    "cv_similarities = []\n",
    "\n",
    "xs = list(range(1, num_images))\n",
    "ys = list(range(1, num_images))\n",
    "xs_grid, ys_grid = np.meshgrid(xs, ys)\n",
    "\n",
    "out_path_AllEmbryos = f\"{path_dst}/AllEmbryos/\"\n",
    "\n",
    "for counterEmbryo, embryo_similarities_list in enumerate(all_similarities_array):\n",
    "    \n",
    "    # Export calculate stats and image\n",
    "    embryoId = f\"embryo_{counterEmbryo:03d}\"\n",
    "    average_array, median_array, min_array, max_array, std_array, cv_array = export_images_stats(xs_grid, ys_grid, embryo_similarities_list, out_path_AllEmbryos, embryoId, time_interval)\n",
    "\n",
    "    # store data\n",
    "    avg_similarities.append(average_array)\n",
    "    std_similarities.append(std_array)\n",
    "    cv_similarities.append(cv_array)\n",
    "    print(f\"Embryo: {counterEmbryo}: min {np.amin(std_array)}, max {np.amax(std_array)} \")\n",
    "    \n",
    "\n",
    "    \n",
    "    #print(f\"Embryo: {counterEmbryo}: {average_array.shape} \")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a522d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average similarities over all embryos\n",
    "stacked_arrays = np.stack(avg_similarities, axis=0)\n",
    "average_array, median_array, min_array, max_array, std_array, cv_array = export_images_stats(xs_grid, ys_grid, avg_similarities, path_dst, \"all_embryos\", time_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c595c484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
