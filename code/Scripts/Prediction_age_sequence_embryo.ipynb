{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443f4717",
   "metadata": {},
   "source": [
    "# Aim\n",
    "Predict a trajectory of embryonic stages based on embryo images using Twin Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras import applications, layers, models\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "\n",
    "from twinnet_tools.tnconfig import ProjectConfig\n",
    "\n",
    "config = ProjectConfig(\"twinnet_config\")\n",
    "dir_root_scripts = config.json[\"dir_scripts\"]\n",
    "\n",
    "\n",
    "import glob\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(dir_root_scripts)\n",
    "from twinnet_tools.tngeneral import TNToolsGeneral\n",
    "from twinnet_tools.tninference import TNToolsEmbeddings\n",
    "from twinnet_tools.tninference import TNToolsSimilarities\n",
    "from twinnet_tools.tnmodel import TNToolsNetwork\n",
    "from twinnet_tools.tnplot import TNToolsPlot\n",
    "\n",
    "# Import tools\n",
    "\n",
    "tools_general = TNToolsGeneral()\n",
    "tools_embeddings = TNToolsEmbeddings(size_img=224,\n",
    "                                     size_img_min=250)\n",
    "tools_model = TNToolsNetwork()\n",
    "tools_similarities = TNToolsSimilarities()\n",
    "tools_plot = TNToolsPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rc_params = {'text.usetex': False,\n",
    "                'svg.fonttype': 'none',\n",
    "                'lines.linewidth': 1}\n",
    "\n",
    "mpl.rcParams.update(new_rc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe108d",
   "metadata": {},
   "source": [
    "# 1. Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e27415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet to analyze and refrence information\n",
    "dataSet = \"35_5_J\"\n",
    "refDataSet = \"28_5_ref\"\n",
    "alldatainfo = \"dataSets_info_zfish.txt\"\n",
    "modelName = \"zebrafish_temperature.h5\"\n",
    "referenceImagesName = \"images_jsons_reference_zfish\"\n",
    "\n",
    "# Main paths  \n",
    "srcpath = \"../temperature_zFish/\"\n",
    "codepath = \"../TwinNet-main/code/Scripts/\"\n",
    "\n",
    "# Test datasets paths\n",
    "datapath = os.path.join(srcpath,\"testData\")\n",
    "dir_src_imgs_test = os.path.join(datapath, dataSet)\n",
    "\n",
    "# Info dataSets \n",
    "dataSetsInfo = srcpath+alldatainfo\n",
    "\n",
    "# Model and refrence images\n",
    "path_model = os.path.join(srcpath, \"models/\"+modelName)\n",
    "dir_src_jsons_reference = os.path.join(codepath, referenceImagesName) \n",
    "\n",
    "# Output \n",
    "dir_dst =  os.path.join(srcpath,\"results\")\n",
    "sufix_out = dataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6063e1",
   "metadata": {},
   "source": [
    "Load image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0713ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file dataSetsInfo as a pandas DataFrame with header\n",
    "dataImages = pd.read_csv(dataSetsInfo, sep=',', header=0)\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(dataImages)\n",
    "\n",
    "# Retrieve data form the current dataSet\n",
    "\n",
    "res = dataImages[dataImages['DataSetName'] == dataSet]\n",
    "if not res.empty:\n",
    "    img_time_interval = res.iloc[0, 2]\n",
    "    initial_time =  res.iloc[0, 3]\n",
    "    NumberEmbryos2Analyze = res.iloc[0, 1]\n",
    "    print(f\"Analysing Dataset: {dataSet} -> timeInterval: {img_time_interval} sec, init time: {initial_time} hpf, {NumberEmbryos2Analyze} embryos\")\n",
    "else:\n",
    "    print(\"The dataSet was not found.\")\n",
    "    \n",
    "# Retrieve data form the refrence dataSet   \n",
    "    \n",
    "    \n",
    "res_ref = dataImages[dataImages['DataSetName'] == refDataSet]\n",
    "if not res.empty:\n",
    "    img_time_interval_reference = res_ref.iloc[0, 2]\n",
    "    initial_time_reference =  res_ref.iloc[0, 3]\n",
    "    print(f\"Reference Dataset: {refDataSet} -> timeInterval: {img_time_interval_reference} sec, init time: {initial_time_reference} hpf\")\n",
    "else:\n",
    "    print(\"The Reference dataSet was not found.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02dc842",
   "metadata": {},
   "source": [
    "Load reference image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcbc61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_json_load(path_json):\n",
    "    \"\"\"Load json file.\"\"\"\n",
    "    with open(path_json, 'rb') as JsonFile:\n",
    "        content = json.load(JsonFile)\n",
    "    return content\n",
    "\n",
    "# Data loading\n",
    "\n",
    "json_anchor = sorted(glob.glob(f'{dir_src_jsons_reference}/*.json'))\n",
    "Number_anchors = len(json_anchor)\n",
    "\n",
    "paths_anchor = [None] * Number_anchors\n",
    "for i in range(0, Number_anchors):\n",
    "    paths_anchor[i] = fn_json_load(json_anchor[i])\n",
    "\n",
    "for i in range(0, Number_anchors):\n",
    "    print(paths_anchor[i][0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdf64f",
   "metadata": {},
   "source": [
    "# 2. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049a2ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet50 = tools_model.tn_embedding_load(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b21ed",
   "metadata": {},
   "source": [
    "# 3. Calculate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_image_tiff_parse(path_img, img_size=224, img_size_min=250):\n",
    "    \"\"\"Load TIFF image from path.\"\"\"\n",
    "    img1 = tf.io.read_file(path_img)\n",
    "    img2 = tfio.experimental.image.decode_tiff(img1)\n",
    "    img3 = tf.image.resize_with_crop_or_pad(img2, img_size_min, img_size_min)\n",
    "    img4 = tf.reshape(img3, (img_size_min, img_size_min, 4))\n",
    "    img5 = tf.image.resize(img4, (img_size, img_size))\n",
    "    img6 = tfio.experimental.color.rgba_to_rgb(img5)\n",
    "    img7 = tf.keras.applications.resnet50.preprocess_input(img6)\n",
    "    return img7\n",
    "\n",
    "def fn_images_tiff_parse(paths_images, **kwargs):\n",
    "    \"\"\"Load multiple tiff images from paths to numpy array with tfio.\"\"\"\n",
    "    image_segments = list()\n",
    "    num_images = len(paths_images)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        print(f'[LOADING] Image arrays {i + 1}/{num_images} ...'.ljust(50), end='\\r')\n",
    "        path_image = paths_images[i]\n",
    "        try:\n",
    "            image_segment = fn_image_tiff_parse(path_image, **kwargs)\n",
    "            \n",
    "            image_segments.append(image_segment)\n",
    "        except cv2.error:\n",
    "            pass\n",
    "    return np.array(image_segments)\n",
    "\n",
    "def list_to_embeddings(list_embryos_images, model_embedding):\n",
    "    \"\"\"Generate embeddings for an image set of embryos.\"\"\"\n",
    "    array_imgs = fn_images_tiff_parse(list_embryos_images)\n",
    "    embeds_imgs = tools_embeddings.imgs_to_embeddings(model_embedding, array_imgs)\n",
    "    return embeds_imgs\n",
    "\n",
    "def fn_cosine_similarity(val_a, val_b):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between two values 'val_a' and 'val_b'.\n",
    "    \"\"\"\n",
    "    a = np.squeeze(val_a)\n",
    "    b = np.squeeze(val_b)\n",
    "    return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "def embryo_reference_similarities(embeddings_reference, embeddings_test):\n",
    "    \"\"\"\n",
    "    Loop through list of embeddings. Calculate similarities between each embedding and all of its\n",
    "    previous embeddings.\n",
    "    \"\"\"\n",
    "    Number_anchors = len(embeddings_reference)\n",
    "    column_names = ['Anch_sim_{:02d}'.format(i) for i in range(1, Number_anchors+1)]\n",
    "\n",
    "    similarities = dict()\n",
    "    for i in range(len(embeddings_test)):\n",
    "        print(f'[INFO] {str(i + 1).zfill(3)}/{len(embeddings_test)}'.ljust(50), end='\\r')\n",
    "        df = pd.DataFrame(columns=column_names)      \n",
    "        for j in range(len(embeddings_reference[0])):\n",
    "            anch_sim = [None] * Number_anchors\n",
    "            for k in range(0, Number_anchors):\n",
    "                 anch_sim[k] = fn_cosine_similarity(embeddings_reference[k][j], embeddings_test[i])\n",
    "\n",
    "            df.loc[j] = anch_sim\n",
    "        similarities[i] = df\n",
    "\n",
    "    return similarities\n",
    "\n",
    "def save_sims(sims, dir_dst, **kwargs):\n",
    "    \"\"\"Save similarities stored within dataframes in a dict to a directory by dict keys.\"\"\"\n",
    "    signature = kwargs.get('signature', '')\n",
    "    for _k, _v in sims.items():\n",
    "        print(str(_k).ljust(10), end='\\r')\n",
    "        path_dst = f'{dir_dst}/{signature}similarities_{str(_k).zfill(3)}.csv'\n",
    "        _v.to_csv(path_dst)\n",
    "        \n",
    "def save_json(data, file_path):\n",
    "    \"\"\"Save json file.\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Write the list of numbers to the file in JSON format\n",
    "        json.dump(data, file)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabcc89e",
   "metadata": {},
   "source": [
    "Calculate reference embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6698bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_reference = [None] * Number_anchors\n",
    "for i in range(0, Number_anchors):\n",
    "    embeddings_reference[i] = list_to_embeddings(paths_anchor[i], resnet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bc371",
   "metadata": {},
   "source": [
    "# 4. Calculate embedings and similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2b841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all subfolders in the root folder\n",
    "allData_estimated_dev_age = []\n",
    "allData_experimental_age = []\n",
    "allData_fileNames = []\n",
    "allData_CosDist_extimated_age = []\n",
    "\n",
    "    \n",
    "for folder_name in sorted(os.listdir(dir_src_imgs_test)):\n",
    "    # Construct the full path of the subfolder\n",
    "    subfolder_path = os.path.join(dir_src_imgs_test, folder_name)\n",
    "\n",
    "    # Check if the current path is a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        print(\"Processing subfolder:\", folder_name)\n",
    "        # Load test image paths\n",
    "        imgs_src = sorted(glob.glob(f'{subfolder_path}/*.tif'))\n",
    "        print('***',  len(imgs_src), ' images loaded')\n",
    "        if abs(24 - (len(imgs_src) * img_time_interval / 3600)) > 0.5:\n",
    "            t_interval = (24*3600) / len(imgs_src)\n",
    "            print('!!!!!! Check cosistency time interval expected : ', t_interval)\n",
    "\n",
    "        # Calculate embedings\n",
    "        embeddings_test = list_to_embeddings(imgs_src, resnet50)\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities_test = embryo_reference_similarities(embeddings_reference, embeddings_test)\n",
    "        \n",
    "        # Get median/mean/max similarities from the anchors\n",
    "        sims_stat = list()\n",
    "\n",
    "        for sims_test in similarities_test.values():\n",
    "            # get median of similarities per time point\n",
    "            sims_stat.append(sims_test.max(axis=1))\n",
    "         \n",
    "        df_sims_stat = pd.DataFrame(sims_stat).reset_index(drop=True)\n",
    "        sims_stat = df_sims_stat.values\n",
    "\n",
    "        # Get maxima of similarity sequence\n",
    "        index_ref = np.argmax(sims_stat, axis=1)\n",
    "        max_values = np.amax(sims_stat, axis=1)\n",
    "\n",
    "        # Transform indixes to times\n",
    "        experimental_age  = initial_time + (np.arange(len(imgs_src)) * (img_time_interval / 3600))\n",
    "        estimated_dev_age = initial_time_reference + (index_ref * (img_time_interval_reference / 3600))\n",
    "        \n",
    "        # Store data\n",
    "        allData_experimental_age.append(experimental_age.tolist())\n",
    "        allData_estimated_dev_age.append(estimated_dev_age.tolist())\n",
    "        allData_fileNames.append(folder_name)\n",
    "        allData_CosDist_extimated_age.append(max_values.tolist())\n",
    "        \n",
    "        # plot\n",
    "        #fig, axs = plt.subplots(dpi=300, figsize=(3,3))\n",
    "        #plt.plot(experimental_age,estimated_dev_age)\n",
    "        #plt.plot(experimental_age,experimental_age)\n",
    "        #plt.xlabel('experimental_age')\n",
    "        #plt.ylabel('estimated_dev_age')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85946a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "\n",
    "save_json(allData_estimated_dev_age, os.path.join(dir_dst, 'allData_estimated_dev_age_'+sufix_out+'.json'))\n",
    "save_json(allData_experimental_age, os.path.join(dir_dst, 'allData_experimental_age_'+sufix_out+'.json'))\n",
    "save_json(allData_fileNames, os.path.join(dir_dst, 'allData_fileNames_'+sufix_out+'.json'))\n",
    "save_json(allData_CosDist_extimated_age, os.path.join(dir_dst, 'allData_CosDist_extimated_age_'+sufix_out+'.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce9e71",
   "metadata": {},
   "source": [
    "# 5. Average plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e51d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average and standard deviation per column\n",
    "average = np.mean(allData_estimated_dev_age, axis=0)\n",
    "std_dev = np.std(allData_estimated_dev_age, axis=0)\n",
    "\n",
    "# Generate x-axis values for the plot\n",
    "x = allData_experimental_age[0]\n",
    "\n",
    "# Plot the average curve with standard deviation\n",
    "plt.plot(x, average, label='Average')\n",
    "plt.plot(x, x, label='Reference')\n",
    "plt.fill_between(x, average - std_dev, average + std_dev, alpha=0.2, label='Standard Deviation')\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Experimental age (hpf)')\n",
    "plt.ylabel('Estimated developmental age (hpf)')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda67df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio =   average / np.array(allData_experimental_age[0])\n",
    "\n",
    "# Plot the average curve with standard deviation\n",
    "plt.plot(x, ratio, label='Ratio')\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Experimental age (hpf)')\n",
    "plt.ylabel('Ration Estimated developmental age to Experimental age')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcdabf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea221e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
